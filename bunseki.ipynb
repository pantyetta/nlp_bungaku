{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mecab-python3 unidic-lite matplotlib numpy matplotlib-fontja pandas scipy==1.12 gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 単語分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single book test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "\n",
    "path = \"./dataset/akutagawa/ababababa.txt\"\n",
    "\n",
    "def read_file(path):\n",
    "    f = open(path, encoding=\"shift_jis\")\n",
    "    return f.read()\n",
    "\n",
    "tagger = MeCab.Tagger()\n",
    "\n",
    "text = read_file(path)\n",
    "\n",
    "word_count = {}\n",
    "\n",
    "node = tagger.parseToNode(text)\n",
    "\n",
    "while node:\n",
    "    word = node.surface\n",
    "    if word in word_count.keys():\n",
    "        count = word_count[word]\n",
    "        word_count[word] = count + 1\n",
    "    else:\n",
    "        word_count[word] = 1\n",
    "    node = node.next\n",
    "    \n",
    "word_count = sorted(word_count.items(), key=lambda x:x[1], reverse=True)\n",
    "print(word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single author test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import MeCab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "author_path = \"./dataset/akutagawa\"\n",
    "word_count = {}\n",
    "\n",
    "def scan_file(path) -> list[str]:\n",
    "    try:\n",
    "        with os.scandir(path) as entries:\n",
    "            items = [entry.name for entry in entries if entry.is_file()]\n",
    "        return items\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def read_file(path):\n",
    "    f = open(path, encoding=\"shift_jis\")\n",
    "    return f.read()\n",
    "\n",
    "tagger = MeCab.Tagger()\n",
    "\n",
    "\n",
    "files = scan_file(author_path)\n",
    "for i, file in enumerate(files):\n",
    "    text = read_file(f'{author_path}/{file}')\n",
    "\n",
    "    node = tagger.parseToNode(text)\n",
    "\n",
    "    while node:\n",
    "        word = node.surface\n",
    "        if word in word_count.keys():\n",
    "            count = word_count[word]\n",
    "            word_count[word] = count + 1\n",
    "        else:\n",
    "            word_count[word] = 1\n",
    "        node = node.next\n",
    "    \n",
    "word_list = sorted(word_count.items(), key=lambda x:x[1], reverse=True)\n",
    "# print(word_list)\n",
    "\n",
    "author_count = [item[1] for item in word_list]\n",
    "\n",
    "words = [item[0] for item in word_list[:15]]  # Top 30 words\n",
    "counts = [item[1] for item in word_list[:15]]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(words, counts)\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bast author word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import MeCab\n",
    "\n",
    "folder_path = \"./dataset\"\n",
    "author_word_count = {}\n",
    "\n",
    "def scan_file(path) -> list[str]:\n",
    "    try:\n",
    "        with os.scandir(path) as entries:\n",
    "            items = [entry.name for entry in entries if entry.is_file()]\n",
    "        return items\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "def scan_folder(path) -> list[str]:\n",
    "    try:\n",
    "        with os.scandir(path) as entries:\n",
    "            items = [entry.name for entry in entries]\n",
    "        return items\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def read_file(path):\n",
    "    f = open(path, encoding=\"shift_jis\")\n",
    "    return f.read()\n",
    "\n",
    "tagger = MeCab.Tagger()\n",
    "\n",
    "author_dict = {'akutagawa': [], 'mori': [], 'dazai': []}\n",
    "line_dict = []\n",
    "\n",
    "folders = scan_folder(folder_path)\n",
    "for i, folder in enumerate(folders):\n",
    "    if folder == 'pre':\n",
    "        continue\n",
    "    word_count = {}\n",
    "    files = scan_file(f'{folder_path}/{folder}')\n",
    "    for file in files:\n",
    "        text = read_file(f'{folder_path}/{folder}/{file}')\n",
    "\n",
    "        node = tagger.parseToNode(text)\n",
    "\n",
    "        while node:\n",
    "            word = node.surface\n",
    "            if word in word_count.keys():\n",
    "                count = word_count[word]\n",
    "                word_count[word] = count + 1\n",
    "            else:\n",
    "                word_count[word] = 1\n",
    "            line_dict.append(word)\n",
    "            if word == '。':\n",
    "                author_dict[folder].append(line_dict)\n",
    "                line_dict = []\n",
    "            \n",
    "            node = node.next\n",
    "    word_count = sorted(word_count.items(), key=lambda x:x[1], reverse=True)\n",
    "    author_word_count[folder] = word_count\n",
    "\n",
    "print(author_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib_fontja\n",
    "import pandas as pd\n",
    "\n",
    "n = None\n",
    "r = 0.03\n",
    "\n",
    "akutagawa_list = [item[0] for item in author_word_count['akutagawa'][:n]]\n",
    "dazai_list = [item[0] for item in author_word_count['dazai'][:n]]\n",
    "mori_list = [item[0] for item in author_word_count['mori'][:n]]\n",
    "\n",
    "\n",
    "# 統合リストを作成し、重複を無視\n",
    "labels = list(set(akutagawa_list + dazai_list + mori_list))\n",
    "\n",
    "# 各作家のデータを整形\n",
    "akutagawa_counts = [dict(author_word_count['akutagawa'][:n]).get(label, 0) for label in labels]\n",
    "dazai_counts = [dict(author_word_count['dazai'][:n]).get(label, 0) for label in labels]\n",
    "mori_counts = [dict(author_word_count['mori'][:n]).get(label, 0) for label in labels]\n",
    "\n",
    "total_counts = [(akutagawa_counts[i] + dazai_counts[i] + mori_counts[i]) for i, label in enumerate(labels)]\n",
    "\n",
    "# ラベルごとに値をまとめる\n",
    "combined = list(zip(total_counts, labels, akutagawa_counts, dazai_counts, mori_counts))\n",
    "\n",
    "# 目的のリストに従ってソート\n",
    "sorted_combined = sorted(combined, key=lambda x: x[0], reverse=True)  # ここではtotal_countをキーにソート\n",
    "\n",
    "# ソート後に分解\n",
    "total_counts, labels, akutagawa_counts, dazai_counts, mori_counts = zip(*sorted_combined)\n",
    "\n",
    "stop_df = pd.DataFrame.from_dict(dict(label = labels[:int(len(labels) * r)], count = total_counts[:int(len(total_counts) * r)]))\n",
    "oringin_word_df = pd.DataFrame.from_dict(dict(label = labels[int(len(labels) * r):], count = total_counts[int(len(total_counts) * r):]))\n",
    "stop_df.to_csv(f'./output/stopword_n_{n}.csv')\n",
    "print(\"word count:\", len(labels), f\"remove {r}:\", int(len(labels) * r))\n",
    "print(stop_df)\n",
    "\n",
    "\n",
    "oringin_word_df.to_csv(f'./output/origin_n_{n}.csv')\n",
    "print(\"word count:\", len(labels), f\"remove {r}:\", len(labels) - int(len(labels) * r))\n",
    "print(oringin_word_df)\n",
    "\n",
    "labels_plot = [f'{a} {b}' for a, b in zip(labels, total_counts)]\n",
    "\n",
    "if n != None and len(labels_plot) <= 10:\n",
    "    # グラフを描画\n",
    "    x = np.arange(len(labels_plot))  # ラベルの位置\n",
    "    width = 0.2  # バーの幅\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    bars1 = ax.bar(x - width, akutagawa_counts, width, label='Akutagawa')\n",
    "    bars2 = ax.bar(x, dazai_counts, width, label='Dazai')\n",
    "    bars3 = ax.bar(x + width, mori_counts, width, label='Mori')\n",
    "\n",
    "    # ラベルを追加\n",
    "    ax.set_xlabel('Characters')\n",
    "    ax.set_ylabel('Counts')\n",
    "    ax.set_title('Character Counts by Author')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels_plot)\n",
    "    ax.legend()\n",
    "\n",
    "    # バーのラベルを表示\n",
    "    def add_labels(bars):\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f'{height}',\n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # バーの上に少しずらして表示\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "\n",
    "    add_labels(bars1)\n",
    "    add_labels(bars2)\n",
    "    add_labels(bars3)\n",
    "\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
